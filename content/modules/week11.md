+++
title = "Week 11"
date = 2021-01-15T23:07:09-08:00
weight = 5
chapter = true
pre = "<b></b>"
id = "typeform"
+++

## Week 11: Ethics (*continued*) and Breaking into Data Science

#### Links
  - [Class Slides](https://docs.google.com/presentation/d/1wYAJoA1mJcqr87GFX3D_og_6eNhVYOVqJGAlVyvu3sg/edit?usp=sharing)
  - Data Ethics Film Discussions
    - **The Great Hack**
      1. Are there any benefits to social media marketing?
      2. Is all data collection unethical? Do you think psychological / behavioral analytics is net positive or net negative?
      3. Do you think that social media has shaped your political views? If so, how is that different than your closest friends and family shaping your political views?
      4. Are there worse companies than Cambridge Analytica?
      5. Do you think it’s important for everyone to have the same set of facts? Do you follow people and sources you disagree with? Why or why not?
    - **The Social Dilemma**
      1. Film subject Tristan Harris says, “if something is a tool, it genuinely is just sitting there, waiting patiently [to be used]. If something is not a tool, it’s demanding things from you, it’s seducing you, it’s manipulating you. It wants things from you.” Do you think social media is a tool for you? How might you make it one?
      2. Who do you think is responsible for solving “the social dilemma”? What should they do? Is there anything you can do?
      3. Do you find yourself unconsciously checking your phone or certain apps? Did this, or the impulse to, happen at all while watching the fim? What emotions seem to trigger this behavior?
      4. Film subject Tristan Harris posits that before artificial intelligence overpowers human strength, it will “overpower human weakness.” What does he mean by that? in what ways do you think technology has overpowered your own vulnerabilities? How is it shaping your behaviors day-to-day?
      5. Film subjects Aza Raskin and Renée Diresta have written that there’s “a difference between freedom of speech and freedom of reach.” What do you think they mean by that?
      6. Should we trust an algorithm to make major decisions such as employment, financial, or housing outcomes as well as what information we see? Is it possible for algorithms to be objective when they are written by humans, mostly white upper class Americans in Silicon Valley, who are shaped by their own biases and experiences?
      7. Do you think algorithms that prioritize outrageous and divisive content amplify hate toward minority groups? What should be done?
      8. In desperation, the family in the film uses a Kitchen Safe to lock up their screens, but this solution is short-lived. What is your family’s relationship with your devices and social media at home? Were there any moments between the film’s fictional family that felt particularly resonant?
      9. What are some concrete actions major tech companies could take to better protect children and preserve your family’s time and connection?
    - **Coded Bias**
      1. How do algorithms influence what news we see online or the perspectives we see on social media? How does AI shape the way we all think?
      2. Early AI developers measured the intelli- gence of the technology by its ability to play games, such as chess. Why might this defi- nition of intelligence be limiting? What other forms of intelligence are important measures for technology?
      3. Do you think police or immigration enforcers should be allowed to search databases that store your driver’s license photo or passport photo? Why or why not?
      4. Joy Buolamwini describes Amazon’s response to her research on bias in its products as “a continuation of the experiences I’ve had as a woman of color in tech. Expect to be discredited. Expect your research to be dis- missed.” Is this an experience you can relate to in your work? Why or why not?
      5. How is AI being used during the COVID-19 pandemic? What human rights concerns relat- ed to pandemic data and surveillance should health officials be considering?
      6. How is the tech industry doing when it comes to promoting inclusion in the workforce? What more needs to be done to ensure that everyone has a fair opportunity to work in tech?
      7. What effect do you think a more inclusive workforce would have on the tech industry? Do you think tech products would be less biased? Why or why not?
      8. What promising practices have you seen in teaching tech ethics and/or increasing student inclusion in computer science programs?
      9. What is your vision for AI development in the future? How would you like to see the technology evolve?



